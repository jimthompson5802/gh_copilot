Based on the requirements, we will need the following core classes, functions, and methods:

1. pandas.read_csv: To read the CSV file into a pandas DataFrame.
2. pandas.DataFrame.fillna: To fill missing values with the median of the respective column.
3. pandas.DataFrame.quantile: To calculate the IQR for handling outliers.
4. sklearn.preprocessing.StandardScaler: To perform feature scaling.
5. sklearn.model_selection.train_test_split: To split the data into training and testing sets.
6. sklearn.linear_model.LinearRegression, sklearn.linear_model.Lasso, sklearn.linear_model.ElasticNet: To create the regression models.
7. sklearn.metrics.mean_squared_error: To calculate the loss value (MSE).
8. joblib.dump: To save the models.

Now, let's write the code. We will put everything in a single Python script named `housing_regression.py`.

housing_regression.py
```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Lasso, ElasticNet
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from joblib import dump

# Load data
df = pd.read_csv('../../generate-synthetic-data/workspace/data/housing2.csv')

# Preprocessing
# Fill missing values with median
df.fillna(df.median(), inplace=True)

# Handle outliers using IQR method
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1
df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]

# Feature Scaling
scaler = StandardScaler()
df[df.columns] = scaler.fit_transform(df[df.columns])

# Split data into features and target variable
X = df.drop('MEDV', axis=1)
y = df['MEDV']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train models
models = {
    'Linear Regression': LinearRegression(),
    'Lasso Regression': Lasso(),
    'ElasticNet Regression': ElasticNet()
}

for name, model in models.items():
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    mse = mean_squared_error(y_test, predictions)
    print(f'{name} MSE: {mse}')

    # Save model
    dump(model, f'{name.replace(" ", "_").lower()}_model.joblib')
```

This script first loads the data, then preprocesses it by filling missing values, handling outliers, and scaling features. It then splits the data into training and testing sets, creates and trains the models, calculates and prints the MSE for each model, and finally saves the models.